{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e870992",
   "metadata": {},
   "source": [
    "# Retrain-from-scratch Unlearning on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4e494",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "eb2730c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20806b1f",
   "metadata": {},
   "source": [
    "## Define The FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f7313672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MnistNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28eb30d",
   "metadata": {},
   "source": [
    "## Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "295ae7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                             transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False,\n",
    "                                                download=True, transform=transform)\n",
    "mnist_testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True,\n",
    "                                download=True, transform=transform)\n",
    "mnist_trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size,\n",
    "                                                    shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8642510",
   "metadata": {},
   "source": [
    "## Split Training Set Into Forgetting Set \n",
    "Split the training set in half for unlearning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c5b980fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 60000\n",
      "Unlearn set size: 54000 (90.0%)\n",
      "Retain set size: 6000 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "total_size = len(mnist_trainset)\n",
    "retain_size = int(0.10 * total_size)\n",
    "unlearn_size = total_size - retain_size\n",
    "\n",
    "forgetting_subset, retain_subset = torch.utils.data.random_split(\n",
    "        mnist_trainset, \n",
    "    [unlearn_size, retain_size]\n",
    ")\n",
    "\n",
    "# Used to test if the unlearned set is recognised\n",
    "retain_loader = torch.utils.data.DataLoader(retain_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Used to train the model without the forgotten dataset\n",
    "forget_loader = torch.utils.data.DataLoader(forgetting_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Total training samples: {total_size}\")\n",
    "print(f\"Unlearn set size: {unlearn_size} ({unlearn_size/total_size*100:.1f}%)\")\n",
    "print(f\"Retain set size: {retain_size} ({retain_size/total_size*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42e46d",
   "metadata": {},
   "source": [
    "## Create Neural Network Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "222295fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MnistNN(input_size=784, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6959b51",
   "metadata": {},
   "source": [
    "## Test Untrained Model\n",
    "Test the untrained model to compare later accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d9e3470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy before training: 0.0982000008225441\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(loader, model):\n",
    "        number_correct = 0\n",
    "        number_samples = 0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.to(device).reshape(x.shape[0], -1)\n",
    "                y = y.to(device)\n",
    "                scores = model(x)\n",
    "                _, predictions = scores.max(1)\n",
    "                number_correct += (predictions == y).sum()\n",
    "                number_samples += predictions.size(0)\n",
    "        model.train()\n",
    "        return number_correct / number_samples\n",
    "\n",
    "untrained_model_accuracy = calculate_accuracy(mnist_testloader, model)\n",
    "print(f\"Model accuracy before training: {untrained_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99fa5e8",
   "metadata": {},
   "source": [
    "## Define Model Parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0d970009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: learning rate = 0.005, epochs = 5 and batch size = 32\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=5e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f\"Model Parameters: learning rate = {lr}, epochs = {epochs} and batch size = {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883c3ae",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "85257952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with device: cuda\n",
      "Model trained with average loss: 0.2849 and accuracy: 0.9601999521255493\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training with device: {device}\")\n",
    "total_loss = 0\n",
    "total_batches = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(mnist_trainloader):\n",
    "        data = data.to(device).reshape(data.shape[0], -1)\n",
    "        targets = targets.to(device)\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "average_loss = total_loss / total_batches\n",
    "trained_model_accuracy = calculate_accuracy(mnist_testloader, model)\n",
    "print(f\"Model trained with average loss: {average_loss:.4f} and accuracy: {trained_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960633c",
   "metadata": {},
   "source": [
    "## Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "797a0ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Accuracy After Training: 0.9601999521255493\n"
     ]
    }
   ],
   "source": [
    "global_accuracy_trained = calculate_accuracy(mnist_testloader, model)\n",
    "print(f\"Global Model Accuracy After Training: {global_accuracy_trained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c090065",
   "metadata": {},
   "source": [
    "## Discard Trained Model\n",
    "Erase the trained model by overwriting the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "833fb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistNN(input_size=784, num_classes=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64849e5a",
   "metadata": {},
   "source": [
    "## Test Erased Model\n",
    "Test accuracy to ensure the network has been replaced with a new, untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cbe38f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy before training: 0.0982000008225441\n",
      "Mode accuracy after training: 0.9601999521255493\n",
      "Model accuracy after erasing (current): 0.0957999974489212\n"
     ]
    }
   ],
   "source": [
    "erased_model_accuracy = calculate_accuracy(mnist_testloader, model)\n",
    "print(f\"Model accuracy before training: {untrained_model_accuracy}\")\n",
    "print(f\"Mode accuracy after training: {trained_model_accuracy}\")\n",
    "print(f\"Model accuracy after erasing (current): {erased_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70821bf9",
   "metadata": {},
   "source": [
    "## Retrain Model Without Forgetting Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7e1d9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with device: cuda\n",
      "Model trained with average loss: 0.8253 and accuracy: 0.9001999497413635\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training with device: {device}\")\n",
    "total_loss = 0\n",
    "total_batches = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(retain_loader):\n",
    "        data = data.to(device).reshape(data.shape[0], -1)\n",
    "        targets = targets.to(device)\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "average_loss = total_loss / total_batches\n",
    "unlearned_model_testset_accuracy = calculate_accuracy(mnist_testloader, model)\n",
    "print(f\"Model trained with average loss: {average_loss:.4f} and accuracy: {unlearned_model_testset_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d741417",
   "metadata": {},
   "source": [
    "## Test Unlearned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e8e05850",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearned_model_forgotten_set_accuracy = calculate_accuracy(forget_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbe45d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e7ba991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy after training (Mnist full trainset): 0.9601999521255493\n",
      "\n",
      "Unlearned model accuracy on unlearned set (Other half of trainset): 0.8989999890327454\n",
      "Unlearned model accuracy on test set (One half of trainset): 0.9001999497413635\n",
      "Performance drop on test set: 0.0600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model accuracy after training (Mnist full trainset): {trained_model_accuracy}\")\n",
    "print()\n",
    "print(f\"Unlearned model accuracy on unlearned set (Other half of trainset): {unlearned_model_forgotten_set_accuracy}\")\n",
    "print(f\"Unlearned model accuracy on test set (One half of trainset): {unlearned_model_testset_accuracy}\")\n",
    "print(f\"Performance drop on test set: {trained_model_accuracy - unlearned_model_testset_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d5bde",
   "metadata": {},
   "source": [
    "## Forgetting Effectiveness\n",
    "Testing the data on the unlearned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ab66d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forgetting Effectiveness: 0.8989999890327454 (lower is better)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forgetting Effectiveness: {unlearned_model_forgotten_set_accuracy} (lower is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64f47c",
   "metadata": {},
   "source": [
    "## Utility Preservation\n",
    "Accuracy retention on non-unlearned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b51d17b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Preservation: 0.9375 (closer to 1.0 is better)\n"
     ]
    }
   ],
   "source": [
    "utility_preservation = unlearned_model_testset_accuracy / trained_model_accuracy\n",
    "print(f\"Utility Preservation: {utility_preservation:.4f} (closer to 1.0 is better)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-unlearn-research-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
